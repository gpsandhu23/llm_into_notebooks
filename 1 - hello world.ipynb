{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3867e53f-be36-4181-9e2b-5539736f16fa",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook is designed to guide you through the process of building a Language Learning Model (LLM) application using Langchain and OpenAI's GPT-4 LLM. The goal is to provide a step-by-step explanation of the environment setup, usage of Langchain and OpenAI API, and the integration of LangSmith for better understanding and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa9bfe44-756c-4dea-8384-20b693c30715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file for API access\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37d4f2",
   "metadata": {},
   "source": [
    "### Langchain\n",
    "Langchain is a comprehensive SDK for building LLM applications, offering flexibility to switch between model providers easily. It simplifies the process of invoking LLM APIs, managing outputs, and integrating with various language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5ba49",
   "metadata": {},
   "source": [
    "### Large Language Model\n",
    "Large Language Models (LLMs) like OpenAI's GPT-4 are trained to understand and generate human-like text. They are the backbone of many GenAI applications, enabling a wide range of natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c21561bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# Initialize the model with GPT-4 for our application\n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb5334",
   "metadata": {},
   "source": [
    "### LangSmith\n",
    "LangSmith is a tool for better understanding and debugging LLM applications. It allows for direct interaction with the LLM, facilitating the creation of annotation queues and datasets for testing and improving model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe1c12-60c5-42df-b57f-083bf9e509bb",
   "metadata": {},
   "source": [
    "### Creating Your First Prompt\n",
    "LLMs process messages in different types. SystemMessage defines the role and function of the LLM, guiding it on how to process user inputs (HumanMessage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595e2e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Hola, GP! ¿Cómo estás?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 26, 'total_tokens': 35}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-bfe1dc1d-4968-465d-81aa-c05683a24de7-0', usage_metadata={'input_tokens': 26, 'output_tokens': 9, 'total_tokens': 35})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Define the system and human messages for interaction\n",
    "system_message = \"Respond back to the user greeting in Spanish\"\n",
    "human_message = \"Hello AI! My name is GP\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=human_message),\n",
    "]\n",
    "\n",
    "# Invoke the LLM API with the defined messages\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2cd481-6acb-4168-9c07-d8359f732347",
   "metadata": {},
   "source": [
    "### Output Formatting\n",
    "LangChain's output parsers simplify the process of formatting LLM outputs, allowing for easy extraction of the main text response without the additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c504e7-074c-42ab-abf3-699c5e459a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the string output parser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96254117-5e72-409c-be92-4e23b1cc9e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola GP! ¿Cómo estás?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the parser to format the LLM's output\n",
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd98049b-b7eb-421f-930c-7e3226d301ea",
   "metadata": {},
   "source": [
    "### Model Switching\n",
    "LangChain facilitates easy switching between different LLMs, allowing for flexibility in choosing the most suitable model for specific tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49057490-67bd-4b1a-aa16-38c190772983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "# Switching to Anthropic Claude 3 for comparison\n",
    "model = ChatAnthropic(model=\"claude-3-opus-20240229\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c1c2f7-4187-4401-a477-79be10c4deed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola GP! Mucho gusto en conocerte. Espero que estés teniendo un buen día.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-invoking the model with the new LLM\n",
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3220117-a20a-48bc-bd91-4de16857341f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fb25506-fbb2-4ca5-8dd6-2bf785dcd751",
   "metadata": {},
   "source": [
    "#### Reviewing Traces with LangSmith\n",
    "LangSmith allows for detailed tracing of LLM interactions, providing insights into the model's behavior and facilitating debugging and improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d12be3a-cc86-467b-8e7e-c90a7d5604a4",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "In this notebook, we explored the basics of building LLM applications with Langchain, including environment setup, API usage, output formatting, and model switching. We also introduced LangSmith for better understanding and debugging of LLM applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
