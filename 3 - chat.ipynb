{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "image-placeholder",
   "metadata": {},
   "source": [
    "![](../assets/placeholder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947468ef-9ab4-4b81-89b5-305ba4edbd94",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook is designed to guide you through the process of building a simple chat application using Langchain and OpenAI's GPT-4 LLM. The focus is on demonstrating how to manage chat history for a seamless conversation experience with a stateless LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85847e11-c55c-4fd3-a5ff-5821682b8e83",
   "metadata": {},
   "source": [
    "### Chat\n",
    "A lot of times we don't just want to ask a LLM one question. It actually is a session with some back and forth. To enable this chat experience, we need to keep track of previous messages with chat history. LLMs are stateless and can only deal with information within their context window. So we need to store this chat history separately and pass it to the LLM along with the new message so that it has all the context. This notebook demonstrates how to implement chat history management for maintaining context in conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb22bf21-e74f-4366-ab27-564d0f704820",
   "metadata": {},
   "source": [
    "Let's start by setting up what hello world example we did in notebook one to highlight the need for chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec8fe5a-32af-4749-92c5-0a5e8e0d507e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7382de95-ed85-4ac1-87b4-3dfa221a49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# Initialize the model with GPT-4 for our chat application\n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd01758a-74f5-45fa-b09e-cafcf71b7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "system_message = \"Respond back to the user greeting in Spanish\"\n",
    "human_message = \"Hello AI! My name is GP\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_message),\n",
    "    HumanMessage(content=human_message),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b2b9b4-fea9-4df0-af30-fd86bdce3bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Hola GP! ¿Cómo estás?', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 26, 'total_tokens': 34}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-a549f421-580c-43eb-9bd4-f557e5f8a333-0', usage_metadata={'input_tokens': 26, 'output_tokens': 8, 'total_tokens': 34})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5db52-f0a4-4e87-98d0-feb20da37567",
   "metadata": {},
   "source": [
    "Now let's ask what our previous question was to see if it remembers\n",
    "\n",
    "hint: it won't, as LLMs are stateless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4871816-4407-4add-bd22-6d5076ced26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = \"What is my name?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e52a889-35dd-4821-805a-3565bdc38231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I don't have access to personal information about you, including your name. How can I assist you today?\", response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 12, 'total_tokens': 37}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-d826db5b-16eb-4e85-9b1d-31f054efb12d-0', usage_metadata={'input_tokens': 12, 'output_tokens': 25, 'total_tokens': 37})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(human_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b41c34-e3ab-472b-887d-64d021c6cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n",
    "config = {\"configurable\": {\"session_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773da23d-9d29-4e37-a512-48053b365a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run c99179dd-9059-4562-bf98-18d4028bc500 not found for run e46de6b2-0a10-49d4-afb2-59075820d81d. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Hola GP! ¿Cómo estás?', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 26, 'total_tokens': 34}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-e46de6b2-0a10-49d4-afb2-59075820d81d-0', usage_metadata={'input_tokens': 26, 'output_tokens': 8, 'total_tokens': 34})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(messages, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e07fb2-e5c6-4043-99ea-9b8809035a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 53b39891-62b8-4e66-84a9-351383d9514c not found for run 6d365d42-bc7d-46a9-b2af-84263a9dfef7. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Tu nombre es GP. ¿En qué puedo ayudarte hoy?', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 47, 'total_tokens': 59}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'stop', 'logprobs': None}, id='run-6d365d42-bc7d-46a9-b2af-84263a9dfef7-0', usage_metadata={'input_tokens': 47, 'output_tokens': 12, 'total_tokens': 59})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message = \"What is my name?\"\n",
    "with_message_history.invoke(human_message, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82427c2-d4f4-4170-b579-53c01f0e7db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
